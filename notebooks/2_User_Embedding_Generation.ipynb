{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGyv_Gq-Nd3h",
        "outputId": "f5626bf4-d691-4067-e1e9-228e21bbed28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount the drives\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yjiQtJ5YRnO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating user interaction file"
      ],
      "metadata": {
        "id": "xwRjbkkjQ9TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define File Paths ---\n",
        "print(\"âœ… 1. Defining file paths...\")\n",
        "\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Embedding_Based_Recommendations_Project/Datasets/final_datasets/'\n",
        "MOVIE_CONTENT_PATH = os.path.join(DRIVE_BASE_PATH, 'movie_content_embeddings_multitask.parquet')\n",
        "RATINGS_PATH = os.path.join(DRIVE_BASE_PATH, 'ratings_small.csv')\n",
        "LINKS_PATH = os.path.join(DRIVE_BASE_PATH, 'links_small.csv')\n",
        "OUTPUT_USER_INTERACTIONS_PATH = os.path.join(DRIVE_BASE_PATH, 'user_movie_interactions.parquet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF170TDYRp3S",
        "outputId": "0ceecd21-0721-47e6-9ec7-8ce627584b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 1. Defining file paths...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Load Necessary Data ---\n",
        "print(\"\\nâœ… 2. Loading data files...\")\n",
        "movies_df = pd.read_parquet(MOVIE_CONTENT_PATH)\n",
        "relevant_tmdb_ids = set(movies_df['tmdb_id'].unique())\n",
        "print(f\"Loaded {len(relevant_tmdb_ids)} movie IDs from your main dataset.\")\n",
        "\n",
        "# Load the ratings and links files from the Kaggle dataset\n",
        "ratings_df = pd.read_csv(RATINGS_PATH)\n",
        "links_df = pd.read_csv(LINKS_PATH)\n",
        "print(\"Loaded ratings and links data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obBjtHAfRs7-",
        "outputId": "b14410e2-7ff9-4bee-cb25-cf7cc3a2599d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… 2. Loading data files...\n",
            "Loaded 1983 movie IDs from your main dataset.\n",
            "Loaded ratings and links data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Process and Merge Data ---\n",
        "print(\"\\nâœ… 3. Processing and merging interaction data...\")\n",
        "\n",
        "# Drop rows with missing tmdb_id in the links file and convert to integer\n",
        "links_df.dropna(subset=['tmdbId'], inplace=True)\n",
        "links_df['tmdbId'] = links_df['tmdbId'].astype(int)\n",
        "\n",
        "# Merge ratings with links to get the tmdb_id for each rating\n",
        "interactions = pd.merge(ratings_df, links_df, on='movieId')\n",
        "\n",
        "# Keep only necessary columns\n",
        "interactions = interactions[['userId', 'tmdbId', 'rating', 'timestamp']]\n",
        "interactions.rename(columns={'tmdbId': 'tmdb_id'}, inplace=True)\n",
        "print(f\"Initial number of interactions: {len(interactions)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBLYA2cjRwuq",
        "outputId": "7cb0820a-152e-4556-94a6-ddeefe805489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… 3. Processing and merging interaction data...\n",
            "Initial number of interactions: 99933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Filter for Relevant Interactions ---\n",
        "print(\"\\nâœ… 4. Filtering for relevant movies...\")\n",
        "\n",
        "# Keep only interactions for movies that exist in our main movie content dataset\n",
        "interactions_filtered = interactions[interactions['tmdb_id'].isin(relevant_tmdb_ids)]\n",
        "print(f\"Number of interactions after filtering: {len(interactions_filtered)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBAjLEoGR1CK",
        "outputId": "cac53204-a4be-42e5-c151-2376347924ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… 4. Filtering for relevant movies...\n",
            "Number of interactions after filtering: 4408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Create User Interaction Sequences ---\n",
        "print(\"\\nâœ… 5. Creating user watch history sequences...\")\n",
        "\n",
        "# Sort interactions by user and timestamp to get the correct watch order\n",
        "interactions_sorted = interactions_filtered.sort_values(by=['userId', 'timestamp'])\n",
        "\n",
        "# Group by user and aggregate their watched movie IDs into a list\n",
        "user_watch_history = interactions_sorted.groupby('userId')['tmdb_id'].apply(list).reset_index()\n",
        "user_watch_history.rename(columns={'tmdb_id': 'watched_movie_ids'}, inplace=True)\n",
        "\n",
        "# Filter out users with very few interactions (e.g., less than 5)\n",
        "min_interactions = 5\n",
        "user_watch_history = user_watch_history[user_watch_history['watched_movie_ids'].apply(len) >= min_interactions]\n",
        "print(f\"Found {len(user_watch_history)} users with at least {min_interactions} interactions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YCr2f81SMqF",
        "outputId": "4963cd0d-3111-4633-d234-cb865d066e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… 5. Creating user watch history sequences...\n",
            "Found 269 users with at least 5 interactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Save the Final DataFrame ---\n",
        "print(f\"\\nâœ… 6. Saving final data to '{OUTPUT_USER_INTERACTIONS_PATH}'...\")\n",
        "user_watch_history.to_parquet(OUTPUT_USER_INTERACTIONS_PATH, index=False)\n",
        "\n",
        "print(\"\\nðŸŽ‰ Success! The 'user_movie_interactions.parquet' file has been created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8FggcwiQ29l",
        "outputId": "181367e7-51c5-4977-e90a-c18a9ceef26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… 6. Saving final data to '/content/drive/MyDrive/Embedding_Based_Recommendations_Project/Datasets/final_datasets/user_movie_interactions.parquet'...\n",
            "\n",
            "ðŸŽ‰ Success! The 'user_movie_interactions.parquet' file has been created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "USER Embedding Generation"
      ],
      "metadata": {
        "id": "vge0WJnbSor-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Configuration and Loading ---\n",
        "print(\"âœ… 1. Loading Prerequisite Data...\")\n",
        "\n",
        "# --- IMPORTANT: Update these paths ---\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Embedding_Based_Recommendations_Project/Datasets/final_datasets/'\n",
        "EMBEDDINGS_PATH = os.path.join(DRIVE_BASE_PATH, 'movie_content_embeddings_multitask.parquet')\n",
        "# This should be your user interaction data (e.g., from ratings_small.csv, pre-processed)\n",
        "USER_INTERACTIONS_PATH = os.path.join(DRIVE_BASE_PATH, 'user_movie_interactions.parquet')\n",
        "USER_EMBEDDINGS_MODEL_PATH = os.path.join(DRIVE_BASE_PATH, 'user_update_ffn.pth')\n",
        "FINAL_USER_EMBEDDINGS_PATH = os.path.join(DRIVE_BASE_PATH, 'final_user_embeddings.parquet')\n",
        "\n",
        "\n",
        "# Load movie content embeddings\n",
        "movies_df = pd.read_parquet(EMBEDDINGS_PATH)\n",
        "movie_id_to_embedding = {row['tmdb_id']: row['content_embedding'] for _, row in movies_df.iterrows()}\n",
        "\n",
        "# Load pre-processed user interactions\n",
        "# This DataFrame should have columns: 'userId', 'watched_movie_ids' (a list of tmdb_ids sorted by time)\n",
        "user_interactions_df = pd.read_parquet(USER_INTERACTIONS_PATH)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Data loaded. Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK_LM4R5W9LC",
        "outputId": "aa1f87d4-4237-4cb8-e3e6-35b2ddbc3bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 1. Loading Prerequisite Data...\n",
            "Data loaded. Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. User Embedding Initialization (Warm Start) ---\n",
        "def initialize_user_embeddings(interactions_df, movie_embeddings, dim, n_warm_start):\n",
        "    \"\"\"Initializes user embeddings by averaging their first N watched movies.\"\"\"\n",
        "    print(f\"\\nâœ… 2. Initializing user embeddings with a {n_warm_start}-movie warm start...\")\n",
        "    initial_embeddings = {}\n",
        "    for _, row in tqdm(interactions_df.iterrows(), total=len(interactions_df), desc=\"User Warm Start\"):\n",
        "        user_id = row['userId']\n",
        "        watched_ids = row['watched_movie_ids'][:n_warm_start]\n",
        "\n",
        "        valid_embs = [movie_embeddings[mid] for mid in watched_ids if mid in movie_embeddings]\n",
        "\n",
        "        if valid_embs:\n",
        "            initial_embeddings[user_id] = np.mean(valid_embs, axis=0)\n",
        "        else:\n",
        "            initial_embeddings[user_id] = np.zeros(dim, dtype=np.float32)\n",
        "\n",
        "    print(f\"Initialized embeddings for {len(initial_embeddings)} users.\")\n",
        "    return initial_embeddings\n",
        "\n",
        "initial_user_embeddings = initialize_user_embeddings(user_interactions_df, movie_id_to_embedding, CONTENT_EMBEDDING_DIM, INITIAL_WARM_START_MOVIES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "98ed8f6dd9fe459898fad883ae3f0d7d",
            "5a252da18c26492a87e0677e907890cc",
            "276446c361d74a88a83bb239a9e6921c",
            "4835abc3a451471fb6dc946bdd7fc1e0",
            "e21be9b44460491a8033e11ec053e9b4",
            "4200e4ab3af846909de733f98f58da3d",
            "afe3cb13a4e0486484cd1ae691c4355b",
            "b8ef933b5d564fa0afbc060807131a90",
            "95eafdca324e4b9b8165b5eb8e7d1d9c",
            "4f84029acba34a8f9a8ed795e8369e45",
            "7d5f8c81b32a4720b446293e5d9d6dc7"
          ]
        },
        "id": "NfQ4847pXDk3",
        "outputId": "5b096ae2-df77-4f16-94c1-c0782a13cc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… 2. Initializing user embeddings with a 5-movie warm start...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "User Warm Start:   0%|          | 0/269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98ed8f6dd9fe459898fad883ae3f0d7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized embeddings for 269 users.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. FFN Model Definition with Residual Connection ---\n",
        "class UserUpdateFFN(nn.Module):\n",
        "    \"\"\"\n",
        "    An FFN that learns an *update* to the user embedding.\n",
        "    Includes a residual connection for stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, user_emb_dim, item_emb_dim, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        input_dim = user_emb_dim + item_emb_dim\n",
        "\n",
        "        self.update_net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, user_emb_dim)\n",
        "        )\n",
        "        # The residual connection helps the model learn an additive update\n",
        "        self.residual_connection = nn.Linear(input_dim, user_emb_dim)\n",
        "\n",
        "    def forward(self, prev_user_emb, new_item_emb):\n",
        "        combined_input = torch.cat([prev_user_emb, new_item_emb], dim=1)\n",
        "        # The new embedding is the original embedding plus the learned change\n",
        "        update = self.update_net(combined_input)\n",
        "        residual = self.residual_connection(combined_input)\n",
        "        return residual + update # Classic residual formula\n",
        "\n",
        "user_update_model = UserUpdateFFN(CONTENT_EMBEDDING_DIM, CONTENT_EMBEDDING_DIM).to(device)\n",
        "print(f\"\\nâœ… 3. UserUpdateFFN model instantiated:\\n{user_update_model}\")\n",
        "\n",
        "\n",
        "# --- 4. PyTorch Dataset for FFN Training ---\n",
        "class UserInteractionDataset(Dataset):\n",
        "    \"\"\"A PyTorch Dataset to create training samples for the UserUpdateFFN.\"\"\"\n",
        "    def __init__(self, interactions_df, movie_embeddings, n_warm_start):\n",
        "        self.movie_embeddings = movie_embeddings\n",
        "        self.all_movie_ids = list(movie_embeddings.keys())\n",
        "        self.training_samples = self._create_samples(interactions_df, n_warm_start)\n",
        "\n",
        "    def _create_samples(self, df, n_warm_start):\n",
        "        samples = []\n",
        "        for _, row in df.iterrows():\n",
        "            user_id = row['userId']\n",
        "            watched_ids = row['watched_movie_ids']\n",
        "            if len(watched_ids) <= n_warm_start:\n",
        "                continue\n",
        "\n",
        "            # The warm-start movies define the initial state\n",
        "            initial_history = watched_ids[:n_warm_start]\n",
        "\n",
        "            # Iterate through the rest of the history to create training sequences\n",
        "            for i in range(n_warm_start, len(watched_ids) - 1):\n",
        "                prev_history = watched_ids[:i]\n",
        "                watched_movie_id = watched_ids[i]\n",
        "                next_positive_id = watched_ids[i+1]\n",
        "\n",
        "                # Ensure all necessary movies have embeddings\n",
        "                if watched_movie_id in self.movie_embeddings and next_positive_id in self.movie_embeddings:\n",
        "                    samples.append((user_id, prev_history, watched_movie_id, next_positive_id, watched_ids))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.training_samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_id, prev_history, watched_movie_id, next_pos_id, all_watched = self.training_samples[idx]\n",
        "\n",
        "        # Calculate user embedding based on their history *before* the current interaction\n",
        "        prev_embs = [self.movie_embeddings[mid] for mid in prev_history if mid in self.movie_embeddings]\n",
        "        if not prev_embs: prev_embs = [np.zeros(CONTENT_EMBEDDING_DIM, dtype=np.float32)]\n",
        "        prev_user_emb = np.mean(prev_embs, axis=0)\n",
        "\n",
        "        watched_item_emb = self.movie_embeddings[watched_movie_id]\n",
        "        next_pos_item_emb = self.movie_embeddings[next_pos_id]\n",
        "\n",
        "        # Sample a negative item\n",
        "        while True:\n",
        "            neg_id = np.random.choice(self.all_movie_ids)\n",
        "            if neg_id not in all_watched:\n",
        "                negative_item_emb = self.movie_embeddings[neg_id]\n",
        "                break\n",
        "\n",
        "        return prev_user_emb, watched_item_emb, next_pos_item_emb, negative_item_emb\n",
        "\n",
        "# --- 5. FFN Training Loop ---\n",
        "\n",
        "# Hyperparameters\n",
        "INITIAL_WARM_START_MOVIES = 5\n",
        "CONTENT_EMBEDDING_DIM = 512\n",
        "FFN_HIDDEN_DIM = 256\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "def train_ffn(model, interactions_df, movie_embs, n_warm_start):\n",
        "    \"\"\"The main training function for the UserUpdateFFN.\"\"\"\n",
        "    print(\"\\nâœ… 4. Preparing dataset and training FFN...\")\n",
        "    dataset = UserInteractionDataset(interactions_df, movie_embs, n_warm_start)\n",
        "    if not dataset:\n",
        "        print(\"No training samples generated. Skipping training.\")\n",
        "        return\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    # Triplet loss is a great choice for this contrastive task\n",
        "    loss_function = nn.TripletMarginLoss(margin=0.2)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        total_epoch_loss = 0\n",
        "        for prev_u, watched_i, next_pos_i, neg_i in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
        "            # Move tensors to the correct device\n",
        "            prev_u = prev_u.float().to(device)\n",
        "            watched_i = watched_i.float().to(device)\n",
        "            next_pos_i = next_pos_i.float().to(device)\n",
        "            neg_i = neg_i.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # The model predicts the user's *next* state\n",
        "            updated_u_emb = model(prev_u, watched_i)\n",
        "\n",
        "            # The updated embedding should be close to the next positive item and far from the negative one\n",
        "            loss = loss_function(anchor=updated_u_emb, positive=next_pos_i, negative=neg_i)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_epoch_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Average Triplet Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), USER_EMBEDDINGS_MODEL_PATH)\n",
        "    print(f\"FFN model saved to {USER_EMBEDDINGS_MODEL_PATH}\")\n",
        "\n",
        "train_ffn(user_update_model, user_interactions_df, movie_id_to_embedding, INITIAL_WARM_START_MOVIES)\n",
        "\n",
        "# --- 6. Final User Embedding Generation (Inference) ---\n",
        "def generate_final_embeddings(model, initial_embs, interactions_df, movie_embs, n_warm_start):\n",
        "    \"\"\"Uses the trained FFN to generate the final dynamic embedding for each user.\"\"\"\n",
        "    print(\"\\nâœ… 5. Generating final user embeddings in inference mode...\")\n",
        "    model.eval()\n",
        "    final_user_embeddings = {}\n",
        "\n",
        "    for _, row in tqdm(interactions_df.iterrows(), total=len(interactions_df), desc=\"Final User Updates\"):\n",
        "        user_id = row['userId']\n",
        "        watched_ids = row['watched_movie_ids']\n",
        "        current_user_emb = initial_embs[user_id]\n",
        "\n",
        "        # Iterate through the interactions that happened *after* the warm start\n",
        "        for movie_id in watched_ids[n_warm_start:]:\n",
        "            if movie_id in movie_embs:\n",
        "                item_emb = movie_embs[movie_id]\n",
        "                # Convert to tensors for the model\n",
        "                u_tensor = torch.tensor(current_user_emb, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "                i_tensor = torch.tensor(item_emb, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "                with torch.no_grad():\n",
        "                    # Update the user embedding using the trained model\n",
        "                    current_user_emb = model(u_tensor, i_tensor).cpu().numpy().squeeze()\n",
        "\n",
        "        final_user_embeddings[user_id] = current_user_emb\n",
        "\n",
        "    return final_user_embeddings\n",
        "\n",
        "final_embeddings_dict = generate_final_embeddings(user_update_model, initial_user_embeddings, user_interactions_df, movie_id_to_embedding, INITIAL_WARM_START_MOVIES)\n",
        "\n",
        "# --- 7. Save Results ---\n",
        "print(\"\\nâœ… 6. Saving final user embeddings...\")\n",
        "final_embs_df = pd.DataFrame.from_dict(final_embeddings_dict, orient='index')\n",
        "final_embs_df.index.name = 'userId'\n",
        "final_embs_df.to_parquet(FINAL_USER_EMBEDDINGS_PATH)\n",
        "print(f\"Final user embeddings saved for {len(final_embs_df)} users to {FINAL_USER_EMBEDDINGS_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f34165eb5263425eb26eaf86faa91b9b",
            "39dc32a8f0b64dddb3e3911b25d85cb5",
            "66040abbfca94244ac03ee2bbd20a823",
            "00f5ae9211824d208f885cccf6cf5cbd",
            "3a4fc8ebe2c34b2e85b755acbe385a02",
            "96087a67ace44b53a513f08fd6315a4f",
            "f734c90d55734dafa6f40685d2cbeaec",
            "d6a58385fcd4418881f7ee99d426614f",
            "505fec361b784f0cab2071b53c785b5d",
            "db9c79513320499b9e9f6623732cdde6",
            "135525a530e94128ae1f8dba63501679",
            "f825b04e4294463ebf6c27383381f7bc",
            "0a43fea1e65045b3aeb62bd0bb127d65",
            "e6a5e80b37644d8d99a9fd9dd9188308",
            "6842141b54eb4271bdd950c6b65add70",
            "9b2b7b499d5643d18d6ddc20c3240a9d",
            "b34eb63aa5df4cdda7d2c495b1584b5a",
            "33d8230ebc724311a46f58a85736554e",
            "90b179c787f14100a930b48d81bdab2b",
            "9e20296d0d8940b4967f349dacfadf25",
            "f2c7777e0d254965a5e688c0215df1ea",
            "254370e7f4924c2187229aaebe966551",
            "1e73580d1b414d44937fba046ef1f018",
            "307af777eb9043c1a2fc6876d02af4a3",
            "4da2f51d4b174cd194388b708cd21278",
            "f65d9791999648c0a294bd4c43df2885",
            "9aad8bc1d0c84fe19f2c4aaa6aceeece",
            "cd13956a0ec744faab70dc295215d3b8",
            "e54d1aa30e934b9fa1abfe2ba3cbeaff",
            "29cbd11de0cc40c2a1457b444914605a",
            "9f1c5c576e5d4e93a6c4b214dbe0a22b",
            "dafbdc0ec0364fac948f2e3a5c9bb95f",
            "fc5115de2b81439f86c6ce539af3eec6",
            "12f8b4dee2ee473db2f8c6bb4d13191a",
            "98154971d5fc46eb952e048b5167756b",
            "192ad0108b7c457ab78aca43ab37d9eb",
            "784b8cf5e4b8456e9f8f5df0aeebf36b",
            "c4dc7ad1c73c4dfcb181353916257a00",
            "e2833301892c46c495e8586942d95d3b",
            "7f45023d2f704444b600f3c15f82f361",
            "6cb0fe6fdfc54e8593aec24b06103127",
            "51d9a8ede0f34f6498198e5c09522b51",
            "554f8624a54b4c3f90784c70059d470e",
            "a6ee365049664ef9b7fbfa5fa4b7273a",
            "367ade5605fc47249d24ebe598716bd3",
            "7705202e1ad348b5bc2a12502e1b6405",
            "420e52aaaa0b4dceb97a1c0e46e39055",
            "0787f08811494606b00d7b929f83b908",
            "a7f75b5c020749b993e5e3459c3e1bbc",
            "ee60adeca97546ebbceb2b7c18e9e406",
            "52d1cb52b9eb4b19a33a4d0abaa4049c",
            "5884e10747974d78aa018917d2efe628",
            "bf741b7f02f348d68f5c8a2a10e29b73",
            "c0ea8f4775cc4259b5eae0255f3ecee5",
            "1a11cee0e3a44bd6ba4be5fdb9adc3ff",
            "dba3d1f1ff694dee91aad9ae4c70a92f",
            "e6769c8f03c84ca5aa5abb85b32b5e82",
            "3b239671cf1045928777b8d0de6e6eb0",
            "0ec021aa38fd4ec98ae68379b9495f7d",
            "7132d41f3a1b4de18115a9349d9a3a4e",
            "a25dd77aba7b475bb731703be2087174",
            "5d88ae39a29743e086b8807b0e6b69ea",
            "0203b8453fea485f9ff7891406fc5821",
            "4138ef3875ed413bb6281bc591435aa2",
            "014af9d45c02457094e3ed9f309aa061",
            "1976dd42a9f64c13a62aa25e57a5fe64",
            "b7dddcbac64442778b4c8834d1fb5137",
            "05428fb3d29940c0aed3ada81d3bd03e",
            "71e0c9a147db40ffbf74e07c6f85d801",
            "54c1a040f8514acc90af22a480af96f7",
            "859864a2d4774b439ac0b6138041d2da",
            "42e3b39afaf04d48abd5a5b2b9ee303b",
            "356cfec9f77d4070a03b4911e9a2e610",
            "d2c06eadcacc41ecaf80930ec744955d",
            "93fff5659a32461c965556b16c371165",
            "b0f495ddb02f4ff6b1e7250c9fce4b40",
            "c74a6167bf7d482c9392c7115960b27a",
            "f7a6a8a8457c4e388e5f89be440ea08a",
            "cf2aaa850ba44517841846a859e123a5",
            "a00a18f9d98b407399315ce8a62a6f81",
            "871012330d5441cf81e5e4c365763a35",
            "1073377ebdee42abbe4d1235b321dfec",
            "00e7ee7dfe704081a7803e8b0a92fa4a",
            "11041001b0ee4fbe96bc88dda227fc5f",
            "269c943c65d14b97a5a92ab6dbee10de",
            "ede881cd9a44420bb2c82d4e145cd26c",
            "c849f67a5dca437ca8e6988711a18509",
            "f5e9ba14cdfd4fbb83aab77a7430fa53",
            "ecaeb2a7567742ee83003284f06aaf21",
            "620a64eb6f8848e2be55703e3b8de7da",
            "e1106bc5f0b5446185ff01cf8688b1a7",
            "8a07183513bd49fb88965e0869237a37",
            "cb32ccba950c43f3af7134b9becb7264",
            "49833b062cf14761a97a848ffff89ffc",
            "831fe85e099f4422b0670b7e0b74e558",
            "36495be3294142a7a037287533633e0d",
            "4e1918d84853480c8b7e3a865c147019",
            "4fa8bfc52f7e44538cb0d9d355ceb54d",
            "2a49cd5b130b499fa1901832f9de6d20",
            "be701107244e465a9de281708373b318",
            "2f00b9b641a5460d8fbbd1d251b182b9",
            "6a7c437085d841a4866b5cd7a7ff774f",
            "b774955be52c43e9b9afd0078218ed52",
            "bbfa5f0d581a4d458a5bdfb977426cc0",
            "bb33448aaf6443eebad18d8282a7ff6b",
            "a8b4c20a862b49bb873f9bbf5601e4f7",
            "c2ff30cfe15c43ec81ff62aec46a58ff",
            "075900ca2e874e76a45d401215911587",
            "e161f26ccb8347d9ba22da54077dd7e8",
            "e70a36a9175b436bb2ba1b48ff4da001",
            "f1f56ebbeba347d781ba83398f80ce2e",
            "eb1ceb4783384ce8a19a030534292e6b",
            "b524eb5dfbf24ecc98ec1a6cb40a0689",
            "1be12d3e64d2472a886c0d6439a1b195",
            "9bc0dd2d9a4d49eda3d136edf7b0493e",
            "3fdb96d8ecd84ee0bc750c2d8474a12d",
            "b919b36103804790a4abff965dd09ee5",
            "9c1648ab3420438ba6446ece9d6a1b49",
            "dc41b816260843588f9ade48b15d1de2",
            "43853966c6fd4ad9a171206f4496c834",
            "15482baed1de48b398b102a722e9deee",
            "f99212b162fe4e45b9caa92f40134864",
            "01485ebaa1cb4800aca5b5888613870d",
            "b4765e2cb50b4948aad3bd2155a36e77",
            "6cf3050e97324917aa71c972d1ac6582",
            "3548cbdf503340a4bc3304d38296f0c9",
            "e2bc91877b5247e08a3d9ea491258a05",
            "7d96f449f6614493bb5546018be44301",
            "62129322bc2a44da8283927618b5b8ef",
            "941ece91f9814b55baea67460d2ef5e4",
            "cbaed4db04b949d786692e0a32967a93",
            "2bfc4521a6484718bf8c241d70987b79"
          ]
        },
        "id": "RzqH03YfSi_v",
        "outputId": "18413121-24f2-4e53-f91e-ad4c7501ddcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 1. Loading Prerequisite Data...\n",
            "Data loaded. Using device: cuda\n",
            "\n",
            "âœ… 2. Initializing user embeddings with a 5-movie warm start...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "User Warm Start:   0%|          | 0/269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f34165eb5263425eb26eaf86faa91b9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized embeddings for 269 users.\n",
            "\n",
            "âœ… 3. UserUpdateFFN model instantiated:\n",
            "UserUpdateFFN(\n",
            "  (update_net): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  )\n",
            "  (residual_connection): Linear(in_features=1024, out_features=512, bias=True)\n",
            ")\n",
            "\n",
            "âœ… 4. Preparing dataset and training FFN...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f825b04e4294463ebf6c27383381f7bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Triplet Loss: 0.1853\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e73580d1b414d44937fba046ef1f018"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Average Triplet Loss: 0.0822\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 3/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12f8b4dee2ee473db2f8c6bb4d13191a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Average Triplet Loss: 0.0640\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 4/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "367ade5605fc47249d24ebe598716bd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Average Triplet Loss: 0.0524\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 5/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dba3d1f1ff694dee91aad9ae4c70a92f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average Triplet Loss: 0.0527\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 6/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7dddcbac64442778b4c8834d1fb5137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Average Triplet Loss: 0.0480\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 7/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7a6a8a8457c4e388e5f89be440ea08a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Average Triplet Loss: 0.0488\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 8/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecaeb2a7567742ee83003284f06aaf21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Average Triplet Loss: 0.0461\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 9/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be701107244e465a9de281708373b318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Average Triplet Loss: 0.0459\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 10/10:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1f56ebbeba347d781ba83398f80ce2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Average Triplet Loss: 0.0429\n",
            "FFN model saved to /content/drive/MyDrive/Embedding_Based_Recommendations_Project/Datasets/final_datasets/user_update_ffn.pth\n",
            "\n",
            "âœ… 5. Generating final user embeddings in inference mode...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Final User Updates:   0%|          | 0/269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f99212b162fe4e45b9caa92f40134864"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… 6. Saving final user embeddings...\n",
            "Final user embeddings saved for 269 users to /content/drive/MyDrive/Embedding_Based_Recommendations_Project/Datasets/final_datasets/final_user_embeddings.parquet\n",
            "\n",
            "Phase complete. You are now ready for the final recommendation and ranking phase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New embeddings sanity check"
      ],
      "metadata": {
        "id": "nSYeOMIvXUrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Setup and Load Data ---\n",
        "print(\"âœ… 1. Loading all necessary data files...\")\n",
        "\n",
        "# --- IMPORTANT: Verify these paths ---\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Embedding_Based_Recommendations_Project/Datasets/final_datasets/'\n",
        "USER_EMBEDDINGS_PATH = os.path.join(DRIVE_BASE_PATH, 'final_user_embeddings.parquet')\n",
        "MOVIE_EMBEDDINGS_PATH = os.path.join(DRIVE_BASE_PATH, 'movie_content_embeddings_multitask.parquet')\n",
        "USER_INTERACTIONS_PATH = os.path.join(DRIVE_BASE_PATH, 'user_movie_interactions.parquet')\n",
        "\n",
        "# Load the final user embeddings we want to validate\n",
        "user_embs_df = pd.read_parquet(USER_EMBEDDINGS_PATH)\n",
        "\n",
        "# Load movie data for titles, genres, and embeddings\n",
        "movies_df = pd.read_parquet(MOVIE_EMBEDDINGS_PATH)\n",
        "movie_embeddings = np.array(movies_df['content_embedding'].tolist())\n",
        "\n",
        "# Load user interaction data to see what they actually watched\n",
        "interactions_df = pd.read_parquet(USER_INTERACTIONS_PATH)\n",
        "user_to_watched_movies = {row['userId']: row['watched_movie_ids'] for _, row in interactions_df.iterrows()}\n",
        "\n",
        "print(\"Data loaded successfully.\")\n",
        "\n",
        "\n",
        "# --- 2. Perform Sanity Checks ---\n",
        "print(\"\\nâœ… 2. Performing Sanity Checks on User Embeddings...\")\n",
        "if user_embs_df.isnull().values.any():\n",
        "    print(\"âŒ WARNING: User embeddings contain NaN values!\")\n",
        "else:\n",
        "    print(\"âœ”ï¸ No NaN values found.\")\n",
        "\n",
        "print(f\"âœ”ï¸ Embeddings loaded for {len(user_embs_df)} users with dimension {user_embs_df.shape[1]}\")\n",
        "\n",
        "\n",
        "# --- 3. Validation Function ---\n",
        "def validate_user_recommendations(user_id, top_n=10):\n",
        "    \"\"\"\n",
        "    Finds the top N movie recommendations for a user and compares them to their watch history.\n",
        "    \"\"\"\n",
        "    if user_id not in user_embs_df.index:\n",
        "        print(f\"âŒ ERROR: User ID {user_id} not found in the embeddings file.\")\n",
        "        return\n",
        "\n",
        "    # Get the user's embedding vector\n",
        "    user_vector = user_embs_df.loc[user_id].values.reshape(1, -1)\n",
        "\n",
        "    # --- Get User's Watch History for Comparison ---\n",
        "    watched_movie_ids = user_to_watched_movies.get(user_id, [])\n",
        "    watched_movies_info = movies_df[movies_df['tmdb_id'].isin(watched_movie_ids)]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"VALIDATION FOR USER: {user_id}\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\n--- This user has watched {len(watched_movie_ids)} movies. Some examples include: ---\")\n",
        "    for _, movie in watched_movies_info.head(5).iterrows():\n",
        "        print(f\"  - {movie['title']} (Genre: {movie['primary_genre']})\")\n",
        "\n",
        "    # --- Calculate Recommendations ---\n",
        "    # Compute cosine similarity between the user and all movies\n",
        "    similarity_scores = cosine_similarity(user_vector, movie_embeddings)[0]\n",
        "\n",
        "    # Get the indices of the top N most similar movies\n",
        "    top_movie_indices = np.argsort(similarity_scores)[::-1][:top_n]\n",
        "\n",
        "    print(f\"\\n--- Top {top_n} Movie Recommendations based on their Embedding: ---\")\n",
        "    for i, idx in enumerate(top_movie_indices):\n",
        "        movie_info = movies_df.iloc[idx]\n",
        "        title = movie_info['title']\n",
        "        genre = movie_info['primary_genre']\n",
        "        score = similarity_scores[idx]\n",
        "\n",
        "        # Check if the user has already seen this recommended movie\n",
        "        watched_marker = \"âœ… (Already Watched)\" if movie_info['tmdb_id'] in watched_movie_ids else \"\"\n",
        "\n",
        "        print(f\"{i+1}. {title:<40} | Genre: {genre:<15} | Similarity: {score:.4f} {watched_marker}\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "\n",
        "# --- 4. Run Validation on a Few Sample Users ---\n",
        "# Pick a few user IDs from your dataset to test their profiles\n",
        "# You can find user IDs by running `print(user_embs_df.index[:10].tolist())`\n",
        "sample_user_ids = user_embs_df.index[:3].tolist() # Let's test the first 3 users\n",
        "\n",
        "for user_id in sample_user_ids:\n",
        "    validate_user_recommendations(user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0plvQk-Te6a",
        "outputId": "b28062f8-22b2-4b73-8f64-ebf267520fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 1. Loading all necessary data files...\n",
            "Data loaded successfully.\n",
            "\n",
            "âœ… 2. Performing Sanity Checks on User Embeddings...\n",
            "âœ”ï¸ No NaN values found.\n",
            "âœ”ï¸ Embeddings loaded for 269 users with dimension 512\n",
            "\n",
            "================================================================================\n",
            "VALIDATION FOR USER: 2\n",
            "================================================================================\n",
            "\n",
            "--- This user has watched 7 movies. Some examples include: ---\n",
            "  - Addams Family Values (Genre: Comedy)\n",
            "  - Waterworld (Genre: Adventure)\n",
            "  - Nine Months (Genre: Comedy)\n",
            "  - Outbreak (Genre: Action)\n",
            "  - The Madness of King George (Genre: Comedy)\n",
            "\n",
            "--- Top 10 Movie Recommendations based on their Embedding: ---\n",
            "1. The Godfather: Part III                  | Genre: Crime           | Similarity: 0.1862 \n",
            "2. The Proposition                          | Genre: Drama           | Similarity: 0.1755 \n",
            "3. Hannibal                                 | Genre: Crime           | Similarity: 0.1624 \n",
            "4. The Mummy                                | Genre: Adventure       | Similarity: 0.1589 \n",
            "5. Donnie Brasco                            | Genre: Crime           | Similarity: 0.1558 \n",
            "6. Meet Joe Black                           | Genre: Fantasy         | Similarity: 0.1556 \n",
            "7. Payback                                  | Genre: Drama           | Similarity: 0.1538 \n",
            "8. Outbreak                                 | Genre: Action          | Similarity: 0.1529 âœ… (Already Watched)\n",
            "9. Turn It Up                               | Genre: Action          | Similarity: 0.1512 \n",
            "10. Quiz Show                                | Genre: History         | Similarity: 0.1502 âœ… (Already Watched)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "VALIDATION FOR USER: 5\n",
            "================================================================================\n",
            "\n",
            "--- This user has watched 5 movies. Some examples include: ---\n",
            "  - Mr. & Mrs. Smith (Genre: Action)\n",
            "  - Miss Congeniality (Genre: Comedy)\n",
            "  - Moulin Rouge! (Genre: Drama)\n",
            "  - The Godfather: Part III (Genre: Crime)\n",
            "  - Harry Potter and the Chamber of Secrets (Genre: Adventure)\n",
            "\n",
            "--- Top 10 Movie Recommendations based on their Embedding: ---\n",
            "1. Hamlet                                   | Genre: Drama           | Similarity: 0.9268 \n",
            "2. Robin Hood                               | Genre: Drama           | Similarity: 0.9197 \n",
            "3. Germinal                                 | Genre: Drama           | Similarity: 0.9188 \n",
            "4. The Edge                                 | Genre: Action          | Similarity: 0.9174 \n",
            "5. The Mummy                                | Genre: Adventure       | Similarity: 0.9155 \n",
            "6. Little Odessa                            | Genre: Action          | Similarity: 0.9142 \n",
            "7. Grand Piano                              | Genre: Thriller        | Similarity: 0.9115 \n",
            "8. Frank Herbert's Children of Dune         | Genre: Drama           | Similarity: 0.9103 \n",
            "9. The Canterville Ghost                    | Genre: TV Movie        | Similarity: 0.9096 \n",
            "10. Nuns on the Run                          | Genre: Comedy          | Similarity: 0.9092 \n",
            "\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "VALIDATION FOR USER: 9\n",
            "================================================================================\n",
            "\n",
            "--- This user has watched 6 movies. Some examples include: ---\n",
            "  - The Thin Red Line (Genre: Drama)\n",
            "  - Payback (Genre: Drama)\n",
            "  - Sliding Doors (Genre: Comedy)\n",
            "  - My Blue Heaven (Genre: Action)\n",
            "  - Contact (Genre: Drama)\n",
            "\n",
            "--- Top 10 Movie Recommendations based on their Embedding: ---\n",
            "1. Quiz Show                                | Genre: History         | Similarity: 0.1603 \n",
            "2. Steel                                    | Genre: Science Fiction | Similarity: 0.1536 \n",
            "3. The Godfather: Part III                  | Genre: Crime           | Similarity: 0.1463 \n",
            "4. The Lord of the Rings: The Two Towers    | Genre: Adventure       | Similarity: 0.1391 \n",
            "5. Contact                                  | Genre: Drama           | Similarity: 0.1379 âœ… (Already Watched)\n",
            "6. The Mummy                                | Genre: Adventure       | Similarity: 0.1367 \n",
            "7. Meet Joe Black                           | Genre: Fantasy         | Similarity: 0.1365 \n",
            "8. Jumper                                   | Genre: Adventure       | Similarity: 0.1352 \n",
            "9. The Proposition                          | Genre: Drama           | Similarity: 0.1332 \n",
            "10. Moulin Rouge!                            | Genre: Drama           | Similarity: 0.1303 \n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------"
      ],
      "metadata": {
        "id": "XaeDLBA3Sj1P"
      }
    }
  ]
}